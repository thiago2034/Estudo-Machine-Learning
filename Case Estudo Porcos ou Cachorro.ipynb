{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc898285",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.24.2-cp38-cp38-win_amd64.whl (6.9 MB)\n",
      "Collecting scipy>=0.19.1\n",
      "  Downloading scipy-1.7.0-cp38-cp38-win_amd64.whl (33.7 MB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting numpy>=1.13.3\n",
      "  Downloading numpy-1.21.0-cp38-cp38-win_amd64.whl (14.0 MB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1321 sha256=648a828e87ae01590835a4edc06d367ba87a726e4064d0f77902ef6837490dc8\n",
      "  Stored in directory: c:\\users\\thiago.araujo\\appdata\\local\\pip\\cache\\wheels\\22\\0b\\40\\fd3f795caaa1fb4c6cb738bc1f56100be1e57da95849bfc897\n",
      "Successfully built sklearn\n",
      "Installing collected packages: numpy, scipy, threadpoolctl, joblib, scikit-learn, sklearn\n",
      "Successfully installed joblib-1.0.1 numpy-1.21.0 scikit-learn-0.24.2 scipy-1.7.0 sklearn-0.0 threadpoolctl-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4eb70302",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91962231",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Meu modelo\n",
    "\n",
    "porco1 = [0,1,0]\n",
    "porco2 = [0,1,1]\n",
    "porco3 = [1,1,0]\n",
    "\n",
    "cachorro1 = [0,1,1]\n",
    "cachorro2 = [1,0,1]\n",
    "cachorro3=  [1,1,1]\n",
    "\n",
    "dados = [porco1, porco2, porco3, cachorro1, cachorro2, cachorro3]\n",
    "\n",
    "# 1 = cachorro 2 = porco\n",
    "\n",
    "classes = [ 1,1,1,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59f6c66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instanciando o LinearSVC\n",
    "model = LinearSVC()\n",
    "#Criando um modelo utilizando o FIT\n",
    "model.fit(dados, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2977d8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Criando um animal com atributos alguns atributos e pedindo pro o modelo predizer se ele é cachorro = 1 ou porco = 0\n",
    "animal_misterioso = [1,1,1]\n",
    "model.predict([animal_misterioso])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f95c31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "misterio1 = [1,1,1]\n",
    "misterio2 = [1,1,0]\n",
    "misterio3 = [0,1,1]\n",
    "\n",
    "testes = [misterio1, misterio2, misterio3]\n",
    "previsoes = model.predict(testes)\n",
    "\n",
    "testes_classes = [0,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73aa0106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de acerto : 66.66666666666666\n"
     ]
    }
   ],
   "source": [
    "#Calculando minha acuracia na mão\n",
    "corretos = (previsoes == testes_classes).sum()\n",
    "total = len(testes)\n",
    "taxa_de_acerto = corretos/total\n",
    "print(f'Taxa de acerto : {taxa_de_acerto * 100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6871fa51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de acerto : 66.66666666666666\n"
     ]
    }
   ],
   "source": [
    "#Calculando minha acuracia utilizando a função accuracy_score do skleanr\n",
    "taxa_de_acerto = accuracy_score(testes_classes, previsoes)\n",
    "print(f'Taxa de acerto : {taxa_de_acerto * 100}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
